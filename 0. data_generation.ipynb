{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.preprocessing import get_texts\n",
    "from utils.preprocessing import get_texts, stop_words\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esg_score = pd.read_excel(\"data/esg_score.xlsx\", sheet_name = \"data\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = df_esg_score['sector'].unique().tolist()\n",
    "sectors = sectors[:-1] # drop nan\n",
    "score_type = ['environmentScore', \"socialScore\", \"governanceScore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through sectors\n",
    "for s in tqdm(sectors):\n",
    "    \n",
    "    # iterate through scores\n",
    "    for t in score_type:\n",
    "        tickers = df_esg_score[df_esg_score[\"sector\"] == s][\"Company\"]\n",
    "        esgs = df_esg_score[df_esg_score[\"sector\"] == s][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]\n",
    "\n",
    "        score = esgs[t]\n",
    "\n",
    "        # alpha value sets the threshold for good and bad scores\n",
    "        alpha = 0.5\n",
    "        upper_score = np.quantile(score, 1 - alpha)\n",
    "        lower_score = np.quantile(score, alpha)\n",
    "\n",
    "\n",
    "        bad_companies = esgs[esgs[t] > upper_score][\"Company\"].values\n",
    "        good_companies = esgs[esgs[t] < lower_score][\"Company\"].values\n",
    "\n",
    "\n",
    "        \n",
    "        #training set\n",
    "        train_bad=random.sample(list(bad_companies), int(len(bad_companies)*0.7))\n",
    "        train_good=random.sample(list(good_companies), int(len(good_companies)*0.7))\n",
    "\n",
    "        #validation set\n",
    "        validate_bad = [i for i in bad_companies if i not in train_bad]\n",
    "        validate_good = [i for i in good_companies if i not in train_good]\n",
    "\n",
    "        # validate_good = pd.DataFrame(validate_good) \n",
    "        # validate_bad = pd.DataFrame(validate_bad) \n",
    "\n",
    "\n",
    "        validation = pd.DataFrame({'good':validate_good, 'bad':validate_bad})\n",
    "\n",
    "        #save the list of good and bad companies\n",
    "        validation_path = os.path.join(\"data\", \"validation_data\")\n",
    "        if not os.path.isdir(validation_path):\n",
    "            os.mkdir(validation_path)\n",
    "\n",
    "        validation.to_csv(\"data/validation_data/{}_{}_{}.csv\".format(s[:8], t[:3], alpha))\n",
    "\n",
    "        #training data bad companies scores\n",
    "        train_bad_scores=pd.DataFrame()\n",
    "\n",
    "        for i in train_bad:\n",
    "            df_bad=esgs[esgs['Company'] == i]\n",
    "            train_bad_scores=train_bad_scores.append(df_bad)\n",
    "\n",
    "\n",
    "        #training data good companies scores\n",
    "        train_good_scores=pd.DataFrame()\n",
    "\n",
    "        for i in train_good:\n",
    "            df_good=esgs[esgs['Company'] == i]\n",
    "            train_good_scores =train_good_scores.append(df_good)\n",
    "\n",
    "\n",
    "\n",
    "        # bad_companies_score = esgs[esgs[score_type] > upper_score][score_type].values\n",
    "        # good_companies_score = esgs[esgs[score_type] < lower_score][score_type].values\n",
    "\n",
    "        good_companies_score_training=train_good_scores[score_type].values\n",
    "        bad_companies_score_training=train_bad_scores[score_type].values\n",
    "\n",
    "\n",
    "        avg_bad = np.mean(bad_companies_score_training)\n",
    "        avg_good = np.mean(good_companies_score_training)\n",
    "        \n",
    "        \n",
    "        \n",
    "                ticker_library = pd.read_csv(os.path.join(\"data\", \"tickers.csv\"))\n",
    "        good_cik = []\n",
    "        bad_cik = []\n",
    "        for ticker in train_good:    \n",
    "            try:\n",
    "                # for a given ticker, find its cik number through th ticker library\n",
    "                good_cik.append(ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:])\n",
    "            except:\n",
    "                # if could not find cik, give it a empty cik\n",
    "                good_cik.append('')\n",
    "\n",
    "        for ticker in train_bad:    \n",
    "            try:\n",
    "                # for a given ticker, find its cik number through th ticker library\n",
    "                bad_cik.append(ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:])\n",
    "            except:\n",
    "                # if could not find cik, give it a empty cik\n",
    "                bad_cik.append('')\n",
    "\n",
    "\n",
    "\n",
    "        ret_good = get_texts(good_cik, train_good)\n",
    "        ret_bad = get_texts(bad_cik, train_bad)\n",
    "\n",
    "        good_docs = ret_good[\"docs\"]\n",
    "        bad_docs = ret_bad[\"docs\"]\n",
    "\n",
    "\n",
    "\n",
    "        # TODO: Modify here for different ngram range\n",
    "        n_min = 2\n",
    "        n_max = 3\n",
    "        cv = CountVectorizer(max_df=0.7, stop_words=stop_words, max_features=200, ngram_range=(n_min, n_max))\n",
    "        word_count_vector = cv.fit_transform(good_docs + bad_docs)\n",
    "\n",
    "        feature_names = cv.get_feature_names()\n",
    "        count_feature = word_count_vector.toarray().sum(axis=0)\n",
    "        feature_names = cv.get_feature_names()\n",
    "\n",
    "\n",
    "\n",
    "        d = {\"word\": [], \"good_score\": [], \"bad_score\": [], \"good_score_all\": []\n",
    "        , \"bad_score_all\": [], \"count\": [], \"good_nums\": [], \"bad_nums\": []}\n",
    "\n",
    "        for feature_idx, word in enumerate(feature_names):\n",
    "            good_sum = bad_sum = good_num = bad_num = 0\n",
    "\n",
    "            for i, doc_set in enumerate(good_docs):\n",
    "                if word in doc_set:\n",
    "                    good_num += 1\n",
    "                    good_sum += good_companies_score_training[i]\n",
    "            for i, doc_set in enumerate(bad_docs):\n",
    "                if word in doc_set:\n",
    "                    bad_num += 1\n",
    "                    bad_sum += bad_companies_score_training[i]\n",
    "\n",
    "            # print(\"word: {}\".format(word))\n",
    "            d[\"word\"].append(word) \n",
    "\n",
    "            if good_num:\n",
    "                d[\"good_score\"].append(good_sum / good_num)\n",
    "            else:\n",
    "                d[\"good_score\"].append(0)\n",
    "            if bad_num:\n",
    "                d[\"bad_score\"].append(bad_sum / bad_num)\n",
    "            else:\n",
    "                d[\"bad_score\"].append(0)\n",
    "\n",
    "            d[\"good_score_all\"].append(good_sum / len(good_docs))\n",
    "            d[\"bad_score_all\"].append(bad_sum / len(bad_docs))\n",
    "\n",
    "            d[\"count\"].append(count_feature[feature_idx])\n",
    "            d[\"good_nums\"].append(good_num)\n",
    "            d[\"bad_nums\"].append(bad_num)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            df = pd.DataFrame(data=d)\n",
    "        df[\"diff\"] = abs(df[\"good_nums\"] - df[\"bad_nums\"])\n",
    "        df = df.sort_values(\"diff\", ascending=False)#.head(60)\n",
    "\n",
    "\n",
    "        goodvbad_path = os.path.join(\"data\", \"training_goodvbad\")\n",
    "        if not os.path.isdir(goodvbad_path):\n",
    "            os.mkdir(goodvbad_path)\n",
    "\n",
    "\n",
    "        df.round(2).to_csv(\"data/training_goodvbad/{}_{}_{}_n{}-{}.csv\".format(s[:8], t[:3], alpha, n_min, n_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESG",
   "language": "python",
   "name": "esg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
